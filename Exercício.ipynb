###################################### 
# Atividade Avaliativa
# Machine Learning
# Author: Ester Pereira Martins
# Professor: Neylson Crepalde
# Exercícios do livro ISL
# Questões 8 (toda), 9 (até letra d), 10 (toda), 13 (toda), 15 (toda)
# Data de entrega: 03/04/2019
######################################

## 8. This question involves the use of simple linear regression on the Auto
## data set.
## (a) Use the lm() function to perform a simple linear regression with
## mpg as the response and horsepower as the predictor. Use the
## summary() function to print the results. Comment on the output.
## For example:
## 3. Linear Regression
## i. Is there a relationship between the predictor and the response?
## ii. How strong is the relationship between the predictor and
## the response?
## iii. Is the relationship between the predictor and the response
## positive or negative?
## iv. What is the predicted mpg associated with a horsepower of
## 98? What are the associated 95 % confidence and prediction
## intervals?









## (b) Plot the response and the predictor. Use the abline() function
## to display the least squares regression line.








## (c) Use the plot() function to produce diagnostic plots of the least
## squares regression fit. Comment on any problems you see with
## the fit.








## 9. This question involves the use of multiple linear regression on the
## Auto data set.
## (a) Produce a scatterplot matrix which includes all of the variables
## in the data set.





## (b) Compute the matrix of correlations between the variables using
## the function cor(). You will need to exclude the name variable, cor() which is qualitative.





## (c) Use the lm() function to perform a multiple linear regression
## with mpg as the response and all other variables except name as
## the predictors. Use the summary() function to print the results.
## Comment on the output. For instance:
## i. Is there a relationship between the predictors and the response?
## ii. Which predictors appear to have a statistically significant
## relationship to the response?
## iii. What does the coefficient for the year variable suggest?




## (d) Use the plot() function to produce diagnostic plots of the linear
## regression fit. Comment on any problems you see with the fit.
## Do the residual plots suggest any unusually large outliers? Does
## the leverage plot identify any observations with unusually high
## leverage?





## 10. This question should be answered using the Carseats data set.
## (a) Fit a multiple regression model to predict Sales using Price,
## Urban, and US.





## (b) Provide an interpretation of each coefficient in the model. Be
## careful—some of the variables in the model are qualitative!







## (c) Write out the model in equation form, being careful to handle
## the qualitative variables properly.





## (d) For which of the predictors can you reject the null hypothesis
## H0 : βj = 0?





## (e) On the basis of your response to the previous question, fit a
## smaller model that only uses the predictors for which there is
## evidence of association with the outcome.





## (f) How well do the models in (a) and (e) fit the data?






## (g) Using the model from (e), obtain 95 % confidence intervals for
## the coefficient(s).







## (h) Is there evidence of outliers or high leverage observations in the
## model from (e)?







## 13. In this exercise you will create some simulated data and will fit simple
## linear regression models to it. Make sure to use set.seed(1) prior to
## starting part (a) to ensure consistent results.
## (a) Using the rnorm() function, create a vector, x, containing 100
## observations drawn from a N(0, 1) distribution. This represents
## a feature, X.










## (b) Using the rnorm() function, create a vector, eps, containing 100
## observations drawn from a N(0, 0.25) distribution i.e. a normal
## distribution with mean zero and variance 0.25.




## (c) Using x and eps, generate a vector y according to the model
## Y = −1+0.5X + . (3.39)
## What is the length of the vector y? What are the values of β0
## and β1 in this linear model?







## (d) Create a scatterplot displaying the relationship between x and
## y. Comment on what you observe.









## (e) Fit a least squares linear model to predict y using x. Comment
## on the model obtained. How do βˆ0 and βˆ1 compare to β0 and
## β1?







## (f) Display the least squares line on the scatterplot obtained in (d).
## Draw the population regression line on the plot, in a different
## color. Use the legend() command to create an appropriate legend.









## (g) Now fit a polynomial regression model that predicts y using x
## and x2. Is there evidence that the quadratic term improves the
## model fit? Explain your answer.






## (h) Repeat (a)–(f) after modifying the data generation process in
## such a way that there is less noise in the data. The model (3.39)
## should remain the same. You can do this by decreasing the variance of the normal distribution used to generate the error term
## in (b). Describe your results.







## (i) Repeat (a)–(f) after modifying the data generation process in
## such a way that there is more noise in the data. The model
## (3.39) should remain the same. You can do this by increasing
## the variance of the normal distribution used to generate the
## error term  in (b). Describe your results.








## (j) What are the confidence intervals for β0 and β1 based on the
## original data set, the noisier data set, and the less noisy data
## set? Comment on your results.








## 15. This problem involves the Boston data set, which we saw in the lab
## for this chapter. We will now try to predict per capita crime rate
## using the other variables in this data set. In other words, per capita
## crime rate is the response, and the other variables are the predictors.
## (a) For each predictor, fit a simple linear regression model to predict
## the response. Describe your results. In which of the models is
## there a statistically significant association between the predictor
## and the response? Create some plots to back up your assertions.







## (b) Fit a multiple regression model to predict the response using
## all of the predictors. Describe your results. For which predictors
## can we reject the null hypothesis H0 : βj = 0?







## (c) How do your results from (a) compare to your results from (b)?
## Create a plot displaying the univariate regression coefficients
## from (a) on the x-axis, and the multiple regression coefficients
## from (b) on the y-axis. That is, each predictor is displayed as a
## single point in the plot. Its coefficient in a simple linear regression model is shown on the x-axis, and its coefficient estimate
## in the multiple linear regression model is shown on the y-axis.










## (d) Is there evidence of non-linear association between any of the
## predictors and the response? To answer this question, for each
## predictor X, fit a model of the form
## Y = β0 + β1X + β2X2 + β3X3 + .











